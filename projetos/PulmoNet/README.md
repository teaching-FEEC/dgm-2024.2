# `PulmoNet: Rede Neuronal Generativa para Imagens TomogrÃ¡ficas Pulmonares`
# `PulmoNet: Generative Neuronal Network for Pulmonary Tomographic Images`

## ApresentaÃ§Ã£o

O presente projeto foi originado no contexto das atividades da disciplina de pÃ³s-graduaÃ§Ã£o *IA376N - IA generativa: de modelos a aplicaÃ§Ãµes multimodais*, 
oferecida no segundo semestre de 2024, na Unicamp, sob supervisÃ£o da Profa. Dra. Paula Dornhofer Paro Costa, do Departamento de Engenharia de ComputaÃ§Ã£o e AutomaÃ§Ã£o (DCA) da Faculdade de Engenharia ElÃ©trica e de ComputaÃ§Ã£o (FEEC).

 |Nome  | RA | EspecializaÃ§Ã£o|
 |--|--|--|
 | Arthur Matheus Do Nascimento | 290906 | Eng. ElÃ©trica |
 | JÃºlia Castro de Paula | 219193 | Eng. ElÃ©trica |
 | LetÃ­cia Levin Diniz | 201438  | Eng. ElÃ©trica |

## Resumo (Abstract)
As tomografias computadorizadas (CT) pulmonares e a segmentaÃ§Ã£o das vias aÃ©reas desempenham um papel crucial no diagnÃ³stico preciso de doenÃ§as pulmonares. 
PropÃµe-se o desenvolvimento da PulmoNet, uma rede para sÃ­ntese de imagens 2D de CTs pulmonares, com o intuito de apoiar redes de segmentaÃ§Ã£o e gerar dados sintÃ©ticos para incorporaÃ§Ã£o em bases de dados para outras redes neurais (e.g. classificadores de tumores).
Utilizando a base de dados ATM'22, implementa-se uma arquitetura GAN, sendo o gerador uma rede Pix2Pix e o discriminador uma PatchGAN, que receberÃ¡ uma mÃ¡scara binÃ¡ria do pulmÃ£o e preencherÃ¡ esta fatia com as vias aÃ©reas.
Tal rede serÃ¡ avaliada em trÃªs anÃ¡lises: qualitativa (observaÃ§Ã£o dos resultados no estÃ¡gio inicial do projeto),  quantitativa (mÃ©tricas FID e SSIM) e utilidade (aplicaÃ§Ã£o do gerador como *feature extractor*).
Os resultados parciais atÃ© o momento nÃ£o foram bem-sucedidos, uma vez que se enfrenta problemas no treinamento, principalmente com relaÃ§Ã£o a velocidade de aprendizado do discriminador comparada ao do gerador.

## DescriÃ§Ã£o do Problema/MotivaÃ§Ã£o
As tomografias computadorizadas (CT) pulmonares, juntamente com a segmentaÃ§Ã£o das vias aÃ©reas, desempenham um papel crucial no diagnÃ³stico preciso de doenÃ§as pulmonares. Ao gerar imagens detalhadas da regiÃ£o torÃ¡cica, ela permite que mÃ©dicos mapeiem a anatomia das vias aÃ©reas antes de procedimentos cirÃºrgicos, avaliando a extensÃ£o de lesÃµes e facilitando o acompanhamento da progressÃ£o de doenÃ§as respiratÃ³rias [[2]](#2). AlÃ©m disso, a CT Ã© fundamental para monitorar a eficÃ¡cia de tratamentos e detectar seus possÃ­veis efeitos colaterais [[5]](#5).

A complexidade e diversidade do corpo humano dificultam a obtenÃ§Ã£o de grandes volumes de dados mÃ©dicos para treinar modelos de aprendizado de mÃ¡quina, como as redes neurais. Essa escassez de dados pode levar a diagnÃ³sticos imprecisos, comprometendo a qualidade do atendimento aos pacientes [[6]](#6). Com as redes generativas Ã© possÃ­vel criar dados de forma a compensar essa escassez, permitindo que as redes aprendam muito mais detalhes do que utilizando apenas aqueles obtidos de exames reais.

[Link para o vÃ­deo de apresentaÃ§Ã£o E1](https://drive.google.com/file/d/1TlpQOlCh_lAI0-jPPMPWOzGZ_werCo3d/view?usp=sharing)

[Link para a apresentaÃ§Ã£o de slides E1](https://docs.google.com/presentation/d/1b8W0Cw1eiTbWlJ0CJJ8eMRA4zyu2iLhYvggi55-mOb0/edit?usp=sharing)

[Link para a apresentaÃ§Ã£o de slides E2](https://docs.google.com/presentation/d/1QH5_WpeTp7kQPSVB78ukK7msn-Tx09pZoM_3dWmeqC4/edit?usp=sharing)

## Objetivo
Este projeto visa gerar imagens sintÃ©ticas de tomografia computadorizada (CT) da regiÃ£o torÃ¡cica de alta fidelidade, tambÃ©m produzindo mÃ¡scaras de segmentaÃ§Ã£o das vias aÃ©reas. A priori, o modelo generativo proposto terÃ¡ como saÃ­da imagens em duas dimensÃµes (2D) de CT da regiÃ£o do tÃ³rax, com grau de realismo suficiente e que possa auxiliar redes de segmentaÃ§Ã£o de vias aÃ©reas. 
AlÃ©m disso, este trabalho tambÃ©m serve como uma primeira etapa de um projeto maior e mais ambicioso, no qual buscar-se-Ã¡ a geraÃ§Ã£o de volumes (imagens 3D) de tomografias pulmonares, uma combinaÃ§Ã£o de fatias que juntas formarÃ£o o equivalente a um exame real.

## Metodologia
### Materiais de ReferÃªncia
Este projeto usarÃ¡ como inspiraÃ§Ã£o inicial o trabalho desenvolvido em [[1]](#1), o qual propÃµe duas arquiteturas baseadas em GANs para a sÃ­ntese de imagens CT pulmonares a partir de mÃ¡scaras binÃ¡rias que segmentam a regiÃ£o pulmonar. Das arquiteturas propostas, inspirar-se-Ã¡ na arquitetura Pix2Pix, na qual o gerador Ã© composto de um encoder que aumenta a profundidade da imagem enquanto diminui suas dimensÃµes, seguido de um decoder que realiza o processo oposto. Tal arquitetura tambÃ©m utiliza conexÃµes residuais. Na arquitetura Pix2Pix, o discriminador Ã© composto por cinco camadas convolucionais, onde as quatro primeiras sÃ£o seguidas por uma camada de ativaÃ§Ã£o *LeakyReLu*, enquanto a Ãºltima Ã© seguida de uma funÃ§Ã£o *sigmoide*. 

AlÃ©m do artigo [[1]](#1), tambÃ©m serÃ£o considerados os trabalhos realizados em [[3]](#3) e [[4]](#4). No primeiro, desenvolveu-se uma GAN condicional para a geraÃ§Ã£o de imagens CT pulmonares a partir de imagens de ressonÃ¢ncia magnÃ©tica. JÃ¡ no segundo, utiliza-se um modelo baseado em GAN para a segmentaÃ§Ã£o do pulmÃ£o em imagens CT que contÃ©m anomalias no tecido pulmonar. Apesar dos objetivos de tais trabalhos nÃ£o serem os mesmos objetivos propostos para o presente projeto, eles servirÃ£o de apoio para proposiÃ§Ã£o de modificaÃ§Ãµes na arquitetura, estratÃ©gias de treino e de validaÃ§Ã£o de resultados.   

### Modelo Proposto
Conforme jÃ¡ discutido na seÃ§Ã£o anterior, apÃ³s um estudo de outros artigos correlatos ao nosso projeto, verificamos que a estratÃ©gia predominante para a sÃ­ntese de CTs pulmonares e conversÃ£o imagem para imagem corresponde a aplicaÃ§Ã£o de GANs (redes adversÃ¡rias generativas).
Em uma GAN, temos uma rede neural "geradora", responsÃ¡vel por sintetizar as distribuiÃ§Ãµes de entrada e retornar saÃ­das similares aos dados reais, e uma rede neural "discriminadora", que deve ser capaz de classificar corretamente suas entradas como "reais" ou "falsas". Com isso, uma boa rede generativa deve ser capaz de enganar o discriminador, ao passo que um bom discriminador deve identificar corretamente os dados sintÃ©ticos em meio aos dados reais.

No caso especÃ­fico da nossa aplicaÃ§Ã£o, utilizaremos como referÃªncia principal as arquiteturas propostas em [[1]](#1). Neste trabalho, uma rede Pix2Pix Ã© utilizada pelo gerador, recebendo uma mÃ¡scara binÃ¡ria com o formato de um pulmÃ£o em um CT e retornando esta imagem 2D preenchida com as vias aÃ©ras de um pulmÃ£o. JÃ¡ a rede discriminadora segue a arquitetura 30 Ã— 30 PatchGAN. Ambas estas estruturas foram inicialmente recomendadas por [[8]](#8).
As duas imagens abaixo ilustram as arquiteturas do gerador e discriminador, respectivamente.

![Arquitetura Pix2Pix proposta para gerador.](figs/arquitetura_gen.png?raw=true)

*Figura 1: Arquitetura Pix2Pix proposta para gerador.*

![Arquitetura PatchGAN proposta para discriminador.](figs/arquitetura_disc.png?raw=true)

*Figura 2: Arquitetura PatchGAN proposta para discriminador.*

A funÃ§Ã£o de loss aplica o critÃ©rio de *Binary Cross Entropy*, conforme a seguinte a equaÃ§Ã£o matemÃ¡tica:

$arg\ min_{ğº}\ max_{ğ·}\ E_{ğ‘¥,ğ‘¦}[log ğ·(ğ‘¥, ğ‘¦)] + E_{ğ‘¥,ğ‘§}[log(1 âˆ’ ğ·(ğ‘¥, ğº(ğ‘¥, ğ‘§)))] + ğœ†E_{ğ‘¥,ğ‘¦,ğ‘§}[â€–ğ‘¦ âˆ’ ğº(ğ‘¥, ğ‘§)â€–_{1}]$

### Bases de Dados e EvoluÃ§Ã£o
Apesar de inspirar-se no artigo [[1]](#1), o desenvolvimento deste projeto utilizarÃ¡ a base de dados ATM'22, cuja descriÃ§Ã£o estÃ¡ na tabela abaixo. Tal base de dados nÃ£o foi usada no desenvolvimento do projeto em [[1]](#1), mas foi escolhida no presente projeto devido a sua amplitude, a presenÃ§a de dados volumÃ©tricos e em razÃ£o das imagens possuÃ­rem a delimitaÃ§Ã£o das vias aÃ©reas obtidas atravÃ©s de especialistas. Os volumes da base ATM'22 foram adquiridos em diferentes clÃ­nicas e considerando diferentes contextos clÃ­nicos. ConstruÃ­da para a realizaÃ§Ã£o de um desafio de segmentaÃ§Ã£o automÃ¡tica de vias aÃ©ria utilizando IA, a base de dados estÃ¡ dividida em 300 volumes para treino, 50 para validaÃ§Ã£o e 150 para teste.

|Base de Dados | EndereÃ§o na Web | Resumo descritivo|
|----- | ----- | -----|
|ATM'22 | https://zenodo.org/records/6590774 e https://zenodo.org/records/6590775  | Esta base contÃ©m 500 volumes CTs pulmonares, nos quais as vias aÃ©reas estÃ£o completamente anotadas, i.e., delimitadas. Tais volumes serÃ£o fatiados em imagens 2-D, segmentados e transformados. Esta base de dados foi utilizada para um desafio de segmentaÃ§Ã£o [[2]](#2).|

Os dados desta base sÃ£o arquivos com extensÃ£o *.nii.gz, e contÃªm todo o volume pulmonar obtido durante um exame de tomografia. Cada arquivo com um volume pulmonar Ã© acompanhado por um outro arquivo de mesma extensÃ£o contendo as anotaÃ§Ãµes feitas por especialistas.
Dado que este trabalho centrarÃ¡-se na geraÃ§Ã£o de imagens sintÃ©ticas em duas dimensÃµes de CTs pulmonares, estes volumes pulmonares serÃ£o fatiados no eixo transversal, assim como ilustrado na imagem abaixo. Como resultado, fatiaremos os 500 volumes pulmores em uma quantidade muito maior de imagens 2D, aumentando o tamanho dos conjuntos de dados disponÃ­veis para treinamento, validaÃ§Ã£o e testes.

![Exemplo de fatia de CT pulmonar obtida a partir da base de dados ATM'22.](figs/dataset_exemplo_fatia.png?raw=true)

*Figura 3: Exemplo de fatia de CT pulmonar obtida a partir da base de dados ATM'22.*

A quantia exata de dados que serÃ£o utilizados depende da configuraÃ§Ã£o da fatia obtida. Isto Ã©, nÃ£o serÃ£o utilizadas todas as fatias do volume pulmonar, mas sim apenas as imagens que apresentarem o pulmÃ£o completo e cercado por tecidos. A partir desta condiÃ§Ã£o, as fatias serÃ£o selecionadas e utilizadas como entrada da rede geradora. Ressalta-se que esta seleÃ§Ã£o Ã© necessÃ¡ria, uma vez que Ã© uma restriÃ§Ã£o da biblioteca em Python *lungmask* [[7]](#7), utilizada para segmentaÃ§Ã£o automÃ¡tica de CTs pulmonares.
TambÃ©m Ã© pertinente destacar que esta segmentaÃ§Ã£o Ã© uma etapa essencial do workflow, posto que os dados de entrada da rede geradora da GAN serÃ£o mÃ¡scaras pulmonares, tal como feito em [[1]](#1).

O grÃ¡fico abaixo ilustra o histograma da base de dados apÃ³s a seleÃ§Ã£o das fatias. Para a construÃ§Ã£o deste histograma, calculou-se a quantidade de pixels de cada imagem que descrevem a regiÃ£o pulmonar (a parte em branco apÃ³s a mÃ¡scara de segmentaÃ§Ã£o). Nota-se que temos muitas imagens com atÃ© 2 mil pixels para compor o pulmÃ£o, depois temos uma queda nesta quantidade de imagens atÃ© algo em torno de 20 mil pixels, seguido por uma nova regiÃ£o de mÃ¡ximo - temos a maior concentraÃ§Ã£o das imagens usadas pela rede generativa com o pulmÃ£o ocupando entre 30 e 40 mil pixels. Depois disso, a quantidade exemplares com mais pixels vai diminuindo gradualmente atÃ© pouco mais de 100 mil pixels.
Um ponto importante a ser mencionado Ã© que apesar do histograma comeÃ§ar em zero, a menor quantia de pixels no conjunto apÃ³s segmentaÃ§Ã£o Ã© de 100 pixels. Ademais, dado que imagens 512 x 512 tÃªm mais de 260 mil pixels, as imagens com a maior quantidade de pixels para a regiÃ£o do pulmÃ£o nÃ£o ocupam nem metade de todos os pixels da imagem.

![Histrograma da quantidade de pixels das fatias selcionadas apÃ³s segmentaÃ§Ã£o das CTS pulmonares da base de dados ATM'22.](figs/histograma_fatias.png?raw=true)

*Figura 4: Histrograma da quantidade de pixels das fatias selcionadas apÃ³s segmentaÃ§Ã£o das CTS pulmonares da base de dados ATM'22.*

A figura abaixo apresenta exemplos de fatias em regiÃµes distintas deste histograma para podermos visualizar a variabilidade dos dados de entrada da rede.
Nota-se que as fatias com menos de 10 mil pixels para descrever o pulmÃ£o praticamente nÃ£o tÃªm regiÃ£o suficiente para ser preenchida com vias aÃ©reas, ao passo que as imagens com mais pixels para a regiÃ£o do pulmÃ£o sÃ£o aquelas mais prÃ³ximas de uma fatia no meio do pulmÃ£o, exibindo a maior Ã¡rea util deste Ã³rgÃ£o.
Com base nestas anÃ¡lises, considera-se descartar imagens com poucos pixels para o pulmÃ£o.

![Exemplos de fatias das CTS pulmonares da base de dados ATM'22 segmentadas.](figs/exemplos_pixels.png?raw=true)

*Figura 5: Exemplos de fatias das CTS pulmonares da base de dados ATM'22 segmentadas.*

AlÃ©m da segmentaÃ§Ã£o dos dados e seleÃ§Ã£o das fatias, a base de dados tambÃ©m passa pelas etapas de normalizaÃ§Ã£o e de transformaÃ§Ã£o para *numpy arrays*, antes de ser utilizada pelas GANs implementadas neste projeto.

### Workflow
O fluxo de trabalho proposto por este projeto, ilustrado na figura a seguir, inicia-se com a obtenÃ§Ã£o da base de dados ATM'22 e seu devido tratamento, conforme detalhado na seÃ§Ã£o anterior.
Utilizando estes dados, alimenta-se a rede generativa com as fatias segmentadas (mÃ¡scaras binÃ¡rias). JÃ¡ a rede discriminadora recebe os dados reais (sem segmentaÃ§Ã£o) e os dados sintÃ©ticos, devendo classificar cada um como "real" ou "falso".
ApÃ³s o treinamento, avalia-se os dados sintÃ©ticos a partir de trÃªs perspectivas: anÃ¡lise qualitativa, anÃ¡lise quantitativa e anÃ¡lise de utilidade, as quais serÃ£o descritas em detalhes nas prÃ³ximas seÃ§Ãµes deste relatÃ³rio.

![Fluxo para treinamento da PulmoNet.](figs/workflow_completo.png?raw=true)

*Figura 6: Fluxo para treinamento da PulmoNet.*

Destaca-se que, em operaÃ§Ã£o (apÃ³s a fase treinamento), espera-se que o modelo receba mÃ¡scaras binÃ¡rias com o formato do pulmÃ£o somadas a um ruÃ­do, retonando o preenchimento da Ã¡rea interna do pulmÃ£o.
Uma mesma mÃ¡scara binÃ¡ria poderÃ¡ gerar imagens sintÃ©ticas distintas, devido ao ruÃ­do aleatÃ³rio adicionado na entrada do modelo.
Os dados sintÃ©ticos deverÃ£o ser bons o suficiente para ajudarem no treinamento de modelo de segmentaÃ§Ã£o das vias aÃ©reas e potencialmente substituir o uso de dados reais, para a preservaÃ§Ã£o da privacidade dos pacientes.

Ademais, na fase atual do projeto, ainda nÃ£o estamos somando um ruÃ­do aleatÃ³rio Ã s fatias segmentadas na entrada do gerador, mas este passo estÃ¡ mapeado para as prÃ³ximas etapas do projeto.

### Ferramentas Relevantes
A ferramenta escolhida para o desenvolvimento da arquitetura dos modelos e de treinamento Ã© o **PyTorch**, em funÃ§Ã£o de sua relevÃ¢ncia na Ã¡rea e familiaridade por parte dos integrantes do grupo.
Ademais, para o desenvolvimento colaborativo dos modelos entre os estudantes, opta-se pela ferramenta de programaÃ§Ã£o **Google Collaboratory**.
JÃ¡ para o versionamento dos modelos e para ajustar seus hiperparÃ¢metros, decidiu-se pela ferramenta **Weights & Biases (Wandb AI)** dentre as opÃ§Ãµes disponÃ­veis no mercado. E, alÃ©m disso, a ferramenta do **GitHub** tambÃ©m auxiliarÃ¡ no versionamento dos algoritmos desenvolvidos.

### MÃ©tricas de AvaliaÃ§Ã£o
Para avaliar a qualidade dos resultados obtidos com o modelo de sÃ­ntese, propÃµe-se trÃªs tipos de avaliaÃ§Ã£o: anÃ¡lise qualitativa, anÃ¡lise quantitativa e anÃ¡lise de utilidade.

#### AnÃ¡lise Qualitativa
Esta estratÃ©gia serÃ¡ utilizada apenas nas etapas iniciais do desenvolvimento do projeto, na qual os prÃ³prios estudantes irÃ£o observar os resultados sintÃ©ticos, sejam eles imagens e/ou  volumes, e compararÃ£o com os dados reais esperados. Com isto, faz-se uma avaliaÃ§Ã£o se a imagem gerada estaria muito distante de uma CT pulmonar ou se o modelo jÃ¡ estaria se encaminhando para bons resultados. ApÃ³s esta etapa, as avaliaÃ§Ãµes do modelo serÃ£o feitas por meio das anÃ¡lises quantitativa e de utiliddade.

#### AnÃ¡lise Quantitativa
A anÃ¡lise quantitativa trata de uma avaliaÃ§Ã£o sobre as imagens a partir dos mÃ©todos **FrÃ©chet Inception Distance (FID)** e **Structural Similarity Index (SSIM)**, os quais sÃ£o utilizados para avaliaÃ§Ã£o de qualidade das imagens sintÃ©ticas e de similaridade com dados reais. Ambas estratÃ©gias foram utilizadas pelos pesquisadores do artigo [[1]](#1), o que permite uma avaliaÃ§Ã£o dos nossos resultados frente a esta outra pesquisa.

Entrando em mais detalhes, a mÃ©trica FID avalia o desempenho da rede generativa e serÃ¡ calculada utilizando uma rede neural prÃ©-treinada *InceptionV3*, que extrairÃ¡ *features* das fatias pulmonares geradas e das fatias originais. Com isso, as distribuiÃ§Ãµes dos dados sintÃ©ticos e dos dados reais, obtidas pelo encoder desta rede, sÃ£o usadas para calcular a FID e, assim, avaliar a qualidade da imagem gerada.
A expressÃ£o matemÃ¡tica que descreve o cÃ¡lculo da FID entre duas distribuiÃ§Ãµes gaussianas criadas pelas *features* da Ãºltima camada de *pooling* do modelo *Inception-v3* Ã© dada por:

$FID = â€–ğœ‡_{ğ‘Ÿ} âˆ’ ğœ‡_{ğ‘”}â€–^{2} + Tr(\sum_{ğ‘Ÿ} + \sum_{ğ‘”} âˆ’ 2(\sum_{ğ‘Ÿ}\sum_{ğ‘”})^{1âˆ•2})$

onde $ğœ‡_{ğ‘Ÿ}$ e $ğœ‡_{ğ‘”}$ sÃ£o as mÃ©dias entre as imagens reais e sintÃ©ticas, e $\sum_{ğ‘Ÿ},\ \sum_{ğ‘”}$ sÃ£o as matrizes de convariÃ¢ncia para os vetores de *features* dos dados reais e gerados, respectivamente.
Quanto menor for o FID, maior a qualidade da imagem gerada.

Por sua vez, a mÃ©trica SSIM compara a imagem gerada com seu respectivo *ground-truth* com base em trÃªs caracterÃ­sticas: luminÃ¢ncia, distorÃ§Ã£o de contraste e perda de correlaÃ§Ã£o estrutural.
Casos as imagens sejam iguais, o resultado desta mÃ©trica serÃ¡ igual a 1, ao passo que se as imagens forem completamente diferentes, o SSIM serÃ¡ nulo.
Ressalta-se que nÃ£o queremos que esta mÃ©trica fique em nenhum deste extremos, mas sim em um valor intermediÃ¡rio.
As expressÃµes matemÃ¡ticas usadas para o cÃ¡lculo desta mÃ©trica sÃ£o:

$SSIM(ğ‘¥, ğ‘¦) = l(ğ‘¥, ğ‘¦) \times ğ‘(ğ‘¥, ğ‘¦) \times ğ‘ (ğ‘¥, ğ‘¦)$

$l(ğ‘¥, ğ‘¦) = \frac{2ğœ‡_{ğ‘¥}ğœ‡_{ğ‘¦} + ğ¶_{1}}{ğœ‡^{2}_{ğ‘¥}+ ğœ‡^{2}_{ğ‘¦} + ğ¶_{1}}$

$ğ‘(ğ‘¥, ğ‘¦) = \frac{2ğœ_{ğ‘¥}ğœ_{ğ‘¦} + ğ¶_{2}}{ğœ^{2}_{ğ‘¥} + ğœ^{2}_{ğ‘¦} + ğ¶_{2}}$

$ğ‘ (ğ‘¥, ğ‘¦) = \frac{ğœ_{ğ‘¥ğ‘¦} + ğ¶_{3}}{ğœ_{ğ‘¥}ğœ_{ğ‘¦} + ğ¶_{3}}$

onde $ğœ‡_{ğ‘¥}$, $ğœ‡_{ğ‘¦}$, $ğœ_{ğ‘¥}$, $ğœ_{ğ‘¦}$, e $ğœ_{ğ‘¥ğ‘¦}$ sÃ£o as mÃ©dias locais, variÃ¢ncias e covariÃ¢ncias cruzadas para as imagens ğ‘¥, ğ‘¦, respectivament. $ğ¶_{1}$, $ğ¶_{2}$ $ğ¶_{3}$ sÃ£o constantes.

#### AnÃ¡lise de Utilidade
Dado que o objetivo do projeto Ã© gerar imagens sintÃ©ticas (2D) de CTs pulmonares realistas, avalia-se nesta etapa duas perspectivas. A primeira delas trata da segmentaÃ§Ã£o das fatias sintÃ©ticas por meio da biblioteca *lungmask* e comparaÃ§Ã£o desta saÃ­da com a mÃ¡scara binÃ¡ria original que gerou esta imagem sintÃ©tica. Isto Ã© feito para avaliar se o gerador conseguiu manter o formato do pulmÃ£o original ou algo prÃ³ximo a isso. Utiliza-se o SSIM para comparaÃ§Ã£o destas duas fatias pulmonares segmentadas.

JÃ¡ a segunda perspectiva trata da utilidade do gerador, em termos de **feature extraction**. Isto Ã©, tomando como inspiraÃ§Ã£o a abordagem explorada em [[9]](#9), implementaremos uma U-Net, com a mesma estrutura da rede geradora Pix2Pix da PulmoNet, para realizar a segmentaÃ§Ã£o das vias aÃ©reas e compararemos o desempenho desta U-Net com uma outra rede que utiliza as *features* extraÃ­das pelo nosso gerador. Esta comparaÃ§Ã£o serÃ¡ avaliada ao comparar as saÃ­das com a prÃ³pria segmentaÃ§Ã£o presente na base de dados ATM'22, feita por especialistas. AlÃ©m disso, serÃ¡ calculado o coeficiente DICE (obtido a partir da precisÃ£o e *recall* da prediÃ§Ã£o), tomando como referÃªncia o artigo [[2]](#2), e considera-se tambÃ©m calcular o tempo de processamento das redes U-Net e U-Net com *features* extraÃ­dos pela nossa Pix2Pix, a fim de verificar se tambÃ©m hÃ¡ uma otimizaÃ§Ã£o neste quesito.

Por fim, Ã© importante destacar o caminho a ser seguido para a avaliaÃ§Ã£o da rede generativa para as saÃ­das em 3D, caso seja possÃ­vel implementÃ¡-las dentro do prazo do projeto. Para esta aplicaÃ§Ã£o, utilizarÃ­amos 5 fatias de CTs pulmonares sequenciais, removerÃ­amos a segunda e a quarta fatias e sinetizarÃ­amos esas fatias faltantes. Feito isso, analisarÃ­amos o volume formado em comparaÃ§Ã£o com o volume original. Com isso, seria possÃ­vel avaliar se a PulmoNet Ã© capaz de gerar imagens relevantes e realistas, alÃ©m de possibilitar sua implementaÃ§Ã£o no auxÃ­lio a **interpolaÃ§Ã£o de CTs pulmonares**.

### Cronograma
O projeto serÃ¡ implementado seguindo o seguinte fluxo lÃ³gico:

![Fluxo lÃ³gico das ativaidades para desenvolvimento da PulmoNet.](figs/fluxo_logico.png?raw=true)

*Figura 7: Fluxo lÃ³gico das ativaidades para desenvolvimento da PulmoNet.*

Dado este fluxo, estipulamos o seguinte cronograma para desenvolvimento do projeto:

| NÂº da Tarefa | DescriÃ§Ã£o                                                                 | Data Prevista de FinalizaÃ§Ã£o | Semanas Entre Etapas |
|--------------|---------------------------------------------------------------------------|------------------------------|----------------------|
| 1            | Leitura de artigos, familiarizaÃ§Ã£o com a base de dados e GANs             | 10/09                        |                      |
| 2            | Primeira versÃ£o da GAN (inspirada no artigo de referÃªncia)                | 24/09                        | 2 semanas            |
| 3            | Estrutura de avaliaÃ§Ã£o bem delimitada                                     | 07/10                        | 2 semanas            |
| 4            | E2                                                                        | 08/10                        | 1 dia                |
| 5            | Primeiros resultados com imagens segmentadas e valores para validaÃ§Ã£o     | 15/10                        | 1 semana             |
| 6            | Fine-tuning e aperfeiÃ§oamento do modelo                                   | 29/10                        | 2 semanas            |
| 7            | Evoluir para redes 3D ou continuar aperfeiÃ§oando o modelo                 | 05/11                        | 1 semana             |
| 8            | E3                                                                        | 25/11                        | 3 semanas            |



## Experimentos, Resultados e DiscussÃ£o dos Resultados
Para a entrega parcial do projeto (E2), jÃ¡ foi feito um estudo de artigos na literatura no contexto do nosso projeto. AlÃ©m disso, seguindo o cronograma do projeto, tambÃ©m foi finalizada a etapa de anÃ¡lise da base de dados e a definiÃ§Ã£o das etapas de prÃ©-processamento, conforme jÃ¡ discutido brevemente na seÃ§Ã£o sobre a base de dados. Mais ainda, tambÃ©m foi realizada a implementaÃ§Ã£o da arquitetura inicial das GANs escolhidas para o projeto, tomando como base o desenvolvimento em [[1]](#1), e iniciou-se a etapa de treinamento deste modelo.

Atualmente, estamos enfrentando dificuldades nesta etapa de treinamento, jÃ¡ que notamos que o discriminador estava ficando muito bom rÃ¡pido demais, nÃ£o permitindo que o gerador conseguisse avanÃ§ar em seu aprendizado. Para solucionar este problema, tentaremos usar a estratÃ©gia de atualizar a *loss* do gerador com mais frequÃªncia do que a do discriminador (a priori, atualizaremos a loss do discriminador a cada 3 batches de atualizaÃ§Ã£o da loss do gerador).

O resultado atual do nosso treinamento Ã© apresentado na figura abaixo. Nota-se que a saÃ­da do gerador ainda estÃ¡ distante do esperado e precisa ser aprimorada.

![Fatia original, fatia segmentada e saÃ­da da PulmoNet na terceira Ã©poca de treinamento.](figs/example_generated_epoch_3.png?raw=true)

*Figura 8: Fatia original, fatia segmentada e saÃ­da da PulmoNet na terceira Ã©poca de treinamento.*

Ademais outros problemas que estamos enfrentando durante a etapa do treinamento tratam do tamanho da nossa base de dados, que Ã© bem grande e resulta em um processamento demorado, e o uso de recursos em GPU.

## ConclusÃ£o
O projeto da rede PulmoNet busca a geraÃ§Ã£o de fatias de CTs pulmonares a partir de mÃ¡scaras binÃ¡rias, em duas dimensÃµes, baseada em GANs. Esta rede utiliza uma arquitetura Pix2Pix para o gerador e uma PatchGAN para o discriminador. SÃ£o usados dados da base pÃºblica ATM'22, cujos dados correspondem a volumes pulmonares de tomografias e segmentaÃ§Ãµes das vias aÃ©reas feitas por especialistas. Para a avaliaÃ§Ã£o da qualidade da rede, propÃµe-se mÃ©todos qualitativos, quantitativos e anÃ¡lises de utilidade.

Seguindo o cronograma do projeto, as etapas atÃ© a entrega E2 foram cumpridas, de maneira que estamos atualmente na fase de treinamento do modelo e implementaÃ§Ã£o dos mÃ©todos de avaliaÃ§Ã£o. No caso do treinamento, estamos enfrentando algumas dificuldades que estÃ£o afetando a qualidade das saÃ­das da rede, principalmente no quesito da velocidade de aprendizado do discriminador frente a do gerador.

Os prÃ³ximos passos do projeto tratam da finalizaÃ§Ã£o do treinamento do modelo, anÃ¡lise das mÃ©tricas de avaliaÃ§Ã£o e fine-tunning e aperfeiÃ§oamento do modelo. Caso tenhamos tempo disponÃ­vel, buscaremos a geraÃ§Ã£o de volumes 3D de CTs pulmonares.

## ReferÃªncias BibliogrÃ¡ficas

<a id="1">[1]</a> : JosÃ© Mendes et al., Lung CT image synthesis using GANs, Expert Systems with Applications, vol. 215, 2023, pp. 119350., https://www.sciencedirect.com/science/article/pii/S0957417422023685.

<a id="2">[2]</a> : Minghui Zhang et al., Multi-site, Multi-domain Airway Tree Modeling (ATM'22): A Public Benchmark for Pulmonary Airway Segmentation, https://arxiv.org/abs/2303.05745.

<a id="3">[3]</a> :  Jacopo Lenkowicz et al., A deep learning approach to generate synthetic CT in low field MR-guided radiotherapy for lung cases, Radiotherapy and Oncology, vol. 176, 2022, pp. 31-38, https://www.sciencedirect.com/science/article/pii/S0167814022042608.

<a id="4">[4]</a> : Swati P. Pawar and Sanjay N. Talbar, LungSeg-Net: Lung field segmentation using generative adversarial network, Biomedical Signal Processing and Control, vol. 64, 2021, 102296, https://www.sciencedirect.com/science/article/pii/S1746809420304158.

<a id="5">[5]</a> : Tekatli, HilÃ¢l et al. â€œArtificial intelligence-assisted quantitative CT analysis of airway changes following SABR for central lung tumors.â€ Radiotherapy and oncology : journal of the European Society for Therapeutic Radiology and Oncology vol. 198 (2024): 110376. doi:10.1016/j.radonc.2024.110376, https://pubmed.ncbi.nlm.nih.gov/38857700/

<a id="6">[6]</a> : Zhang, Ling et al. â€œGeneralizing Deep Learning for Medical Image Segmentation to Unseen Domains via Deep Stacked Transformation.â€ IEEE transactions on medical imaging vol. 39,7 (2020): 2531-2540. doi:10.1109/TMI.2020.2973595, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7393676/

<a id="7">[7]</a> : Hofmanninger, J., Prayer, F., Pan, J. et al. Automatic lung segmentation in routine imaging is primarily a data diversity problem, not a methodology problem. Eur Radiol Exp 4, 50 (2020). https://doi.org/10.1186/s41747-020-00173-2

<a id="8">[8]</a> : Isola, P., Zhu, J. Y., Zhou, T., & Efros, A. A. (2017). Image-to-image translation with conditional adversarial networks. In Proceedings - 30th IEEE conference on computer vision and pattern recognition, CVPR 2017. http://dx.doi.org/10.1109/CVPR.2017. 632, arXiv:1611.07004.

<a id="9">[9]</a> : Radford, A., Metz, L., and Chintala, S., â€œUnsupervised Representation Learning with Deep Convolutional Generative Adversarial Networksâ€, <i>arXiv e-prints</i>, Art. no. arXiv:1511.06434, 2015. doi:10.48550/arXiv.1511.06434.

Documento com as referÃªncias extras identificadas: https://docs.google.com/document/d/1uatPj6byVIEVrvMuvbII6J6-5usOjf8RLrSxLHJ8u58/edit?usp=sharing
