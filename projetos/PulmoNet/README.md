# `PulmoNet: Rede Neuronal Generativa para Imagens Tomogr√°ficas Pulmonares`
# `PulmoNet: Generative Neuronal Network for Pulmonary Tomographic Images`

## Apresenta√ß√£o

O presente projeto foi originado no contexto das atividades da disciplina de p√≥s-gradua√ß√£o *IA376N - IA generativa: de modelos a aplica√ß√µes multimodais*, 
oferecida no segundo semestre de 2024, na Unicamp, sob supervis√£o da Profa. Dra. Paula Dornhofer Paro Costa, do Departamento de Engenharia de Computa√ß√£o e Automa√ß√£o (DCA) da Faculdade de Engenharia El√©trica e de Computa√ß√£o (FEEC).

 |Nome  | RA | Especializa√ß√£o|
 |--|--|--|
 | Arthur Matheus Do Nascimento | 290906 | Eng. El√©trica |
 | J√∫lia Castro de Paula | 219193 | Eng. El√©trica |
 | Let√≠cia Levin Diniz | 201438  | Eng. El√©trica |

## Resumo (Abstract)
> Resumo do objetivo, metodologia e resultados obtidos (na entrega E2 √© poss√≠vel relatar resultados parciais). Sugere-se m√°ximo de 100 palavras.

## Descri√ß√£o do Problema/Motiva√ß√£o
As tomografias computadorizadas (CT) pulmonares, juntamente com a segmenta√ß√£o das vias a√©reas, desempenham um papel crucial no diagn√≥stico preciso de doen√ßas pulmonares. Ao gerar imagens detalhadas da regi√£o tor√°cica, ela permite que m√©dicos mapeiem a anatomia das vias a√©reas antes de procedimentos cir√∫rgicos, avaliando a extens√£o de les√µes e facilitando o acompanhamento da progress√£o de doen√ßas respirat√≥rias [[2]](#2). Al√©m disso, a CT √© fundamental para monitorar a efic√°cia de tratamentos e detectar seus poss√≠veis efeitos colaterais [[5]](#5).

A complexidade e diversidade do corpo humano dificultam a obten√ß√£o de grandes volumes de dados m√©dicos para treinar modelos de aprendizado de m√°quina, como as redes neurais. Essa escassez de dados pode levar a diagn√≥sticos imprecisos, comprometendo a qualidade do atendimento aos pacientes [[6]](#6). Com as redes generativas √© poss√≠vel criar dados de forma a compensar essa escassez, permitindo que as redes aprendam muito mais detalhes do que utilizando apenas aqueles obtidos de exames reais.

[Link para o v√≠deo de apresenta√ß√£o E1](https://drive.google.com/file/d/1TlpQOlCh_lAI0-jPPMPWOzGZ_werCo3d/view?usp=sharing)

[Link para a apresenta√ß√£o de slides E1](https://docs.google.com/presentation/d/1b8W0Cw1eiTbWlJ0CJJ8eMRA4zyu2iLhYvggi55-mOb0/edit?usp=sharing)

[Link para a apresenta√ß√£o de slides E2](https://docs.google.com/presentation/d/1QH5_WpeTp7kQPSVB78ukK7msn-Tx09pZoM_3dWmeqC4/edit?usp=sharing)

## Objetivo
Este projeto visa gerar imagens sint√©ticas de tomografia computadorizada (CT) da regi√£o tor√°cica de alta fidelidade, tamb√©m produzindo m√°scaras de segmenta√ß√£o das vias a√©reas. A priori, o modelo generativo proposto ter√° como sa√≠da imagens em duas dimens√µes (2D) de CT da regi√£o do t√≥rax, com grau de realismo suficiente e que possa auxiliar redes de segmenta√ß√£o de vias a√©reas. 
Al√©m disso, este trabalho tamb√©m serve como uma primeira etapa de um projeto maior e mais ambicioso, no qual buscar-se-√° a gera√ß√£o de volumes (imagens 3D) de tomografias pulmonares, uma combina√ß√£o de fatias que juntas formar√£o o equivalente a um exame real.

## Metodologia
### Materiais de Refer√™ncia
Este projeto usar√° como inspira√ß√£o inicial o trabalho desenvolvido em [[1]](#1), o qual prop√µe duas arquiteturas baseadas em GANs para a s√≠ntese de imagens CT pulmonares a partir de m√°scaras bin√°rias que segmentam a regi√£o pulmonar. Das arquiteturas propostas, inspirar-se-√° na arquitetura Pix2Pix, na qual o gerador √© composto de um encoder que aumenta a profundidade da imagem enquanto diminui suas dimens√µes, seguido de um decoder que realiza o processo oposto. Tal arquitetura tamb√©m utiliza conex√µes residuais. Na arquitetura Pix2Pix, o discriminador √© composto por cinco camadas convolucionais, onde as quatro primeiras s√£o seguidas por uma camada de ativa√ß√£o *LeakyReLu*, enquanto a √∫ltima √© seguida de uma fun√ß√£o *sigmoide*. 

Al√©m do artigo [[1]](#1), tamb√©m ser√£o considerados os trabalhos realizados em [[3]](#3) e [[4]](#4). No primeiro, desenvolveu-se uma GAN condicional para a gera√ß√£o de imagens CT pulmonares a partir de imagens de resson√¢ncia magn√©tica. J√° no segundo, utiliza-se um modelo baseado em GAN para a segmenta√ß√£o do pulm√£o em imagens CT que cont√©m anomalias no tecido pulmonar. Apesar dos objetivos de tais trabalhos n√£o serem os mesmos objetivos propostos para o presente projeto, eles servir√£o de apoio para proposi√ß√£o de modifica√ß√µes na arquitetura, estrat√©gias de treino e de valida√ß√£o de resultados.   

### Modelo Proposto
Conforme j√° discutido na se√ß√£o acima, ap√≥s um estudo de outros artigos correlatos ao nosso projeto, verificamos que a estrat√©gia predominante era a aplica√ß√£o GANs (redes advers√°rias generativas) para a convers√£o imagem para imagem.
Em uma GAN, temos uma rede neural "geradora", respons√°vel por sintetizar as distribui√ß√µes de entrada e retornar sa√≠das similares aos dados reais. Al√©m disso, h√° uma rede neural "discriminadora", que deve ser capaz de classificar corretamente suas entradas como "reais" ou "falsas". Com isso, uma boa rede generativa deve ser capaz de enganar o discriminador, ao passo que um bom discriminador deve identificar corretamente os dados sint√©ticos em meio aos dados reais.

No caso espec√≠fico da nossa aplica√ß√£o, utilizaremos como refer√™ncia principal as arquiteturas propostas em [[1]](#1). Neste trabalho, uma rede Pix2Pix √© utilizada pelo gerador, recebendo uma m√°scara bin√°ria com o formato de um pulm√£o em um CT e retornando esta imagem 2D preenchida com as vias a√©ras de um pulm√£o. J√° a rede discriminadora segue a arquitetura 30 √ó 30 PatchGAN. Ambas estas estruturas foram inicialmente recomendadas por [[8]](#8).
As duas imagens abaixo ilustram as arquiteturas do gerador e discriminador, respectivamente.

![Arquitetura Pix2Pix proposta para gerador.](https://github.com/julia-cdp/dgm-2024.2/tree/readme_e2/projetos/PulmoNet/figs/arquitetura_gen.png?raw=true)

![Arquitetura PatchGAN proposta para discriminador.](https://github.com/julia-cdp/dgm-2024.2/tree/readme_e2/projetos/PulmoNet/figs/arquitetura_disc.png?raw=true)

A fun√ß√£o de loss aplica o crit√©rio de Binary Cross Entropy, conforme a seguinte a equa√ß√£o matem√°tica:

$ arg \ min_ùê∫ \ max_ùê∑ \
E_{ùë•,ùë¶}[log ùê∑(ùë•, ùë¶)]+
E_{ùë•,ùëß}[log(1 ‚àí ùê∑(ùë•, ùê∫(ùë•, ùëß)))]+
ùúÜE_{ùë•,ùë¶,ùëß}[‚Äñùë¶ ‚àí ùê∫(ùë•, ùëß)‚Äñ1
]$

### Bases de Dados e Evolu√ß√£o
Apesar de inspirar-se no artigo [[1]](#1), para o desenvolvimento deste projeto ser√° usada a base de dados ATM'22, cuja descri√ß√£o est√° na tabela abaixo. Tal base de dados n√£o foi usada no desenvolvimento do projeto em [[1]](#1), mas foi escolhida no presente projeto devido a sua amplitude, a presen√ßa de dados volum√©tricos e em raz√£o das imagens possu√≠rem a delimita√ß√£o das vias a√©reas obtidas atrav√©s de especialistas. Os volumes da base ATM'22 foram adquiridos em diferentes cl√≠nicas e considerando diferentes contextos cl√≠nicos. Constru√≠da para a realiza√ß√£o de um desafio de segmenta√ß√£o autom√°tica de vias a√©ria utilizando IA, a base de dados est√° dividida em 300 volumes para treino, 50 para valida√ß√£o e 150 para teste.

|Base de Dados | Endere√ßo na Web | Resumo descritivo|
|----- | ----- | -----|
|ATM'22 | https://zenodo.org/records/6590774 e https://zenodo.org/records/6590775  | Esta base cont√©m 500 volumes CTs pulmonares, nos quais as vias a√©reas est√£o completamente anotadas, i.e., delimitadas. Tais volumes ser√£o fatiados em imagens 2-D, segmentados e transformados. Esta base de dados foi utilizada para um desafio de segmenta√ß√£o [[2]](#2).|

Os dados desta base s√£o arquivos com extens√£o *.nii.gz, e cont√™m todo o volume pulmonar obtido durante um exame de tomografia. Cada arquivo com um volume pulmonar √© acompanhado por um outro arquivo de mesma extens√£o contendo as anota√ß√µes feitas por especialistas.
Dado que este trabalho centrar√°-se na gera√ß√£o de imagens sint√©ticas em duas dimens√µes de CTs pulmonares, estes volumes pulmonares ser√£o fatiados no eixo transversal, assim como ilustrado na imagem abaixo. Como resultado, fatiaremos os 500 volumes pulmores em uma quantidade muito maior de imagens 2D, aumentando o tamanho dos conjuntos de dados dispon√≠veis para treinamento, valida√ß√£o e testes.

![Exemplo de fatia de CT pulmonar obtida a partir da base de dados ATM'22.](https://github.com/julia-cdp/dgm-2024.2/tree/readme_e2/projetos/PulmoNet/figs/dataset_exemplo_fatia.png?raw=true)

A quantia exata de dados que ser√£o utilizados depende da configura√ß√£o da fatia obtida. Isto √©, n√£o ser√£o utilizadas todas as fatias do volume pulmonar, mas sim apenas as imagens que apresentarem o pulm√£o completo e cercado por tecidos. A partir desta condi√ß√£o, as fatias ser√£o selecionadas e utilizadas como entrada da rede geradora. Ressalta-se que esta sele√ß√£o √© necess√°ria, uma vez que √© uma restri√ß√£o da biblioteca em Python lungmask [[7]](#7), utilizada para segmenta√ß√£o autom√°tica de CTs pulmonares.
Tamb√©m √© pertinente destacar que esta segmenta√ß√£o √© uma etapa essencial do workflow, posto que os dados de entrada da rede geradora da GAN ser√£o m√°scaras pulmonares, tal como feito em [[1]](#1).

O gr√°fico abaixo ilutsra o histograma da base de dados ap√≥s a sele√ß√£o das fatias. Para a constru√ß√£o deste histograma, calculou-se a quantidade de pixels de cada imagem que descreviam a regi√£o pulmonar (a parte em branco ap√≥s a m√°scara de segmenta√ß√£o). Nota-se que temos muitas imagens com at√© 2000 pixels para compor o pulm√£o, depois temos uma queda nesta quantidade de imagens at√© algo em torno de 20000 pixels, seguido por uma nova regi√£o de m√°ximo - temos a maior concentra√ß√£o das imagens usadas pela rede generativa com o pulm√£o ocupando entre 30 e 40 mil pixels. Depois disso, a quantidade exemplares com mais pixels vai diminuindo gradualmente at√© pouco mais de 100 mil pixels.
Um ponto importante a ser mencionado √© que apesar do histograma come√ßar em zero, a menor quantia de pixels no conjunto ap√≥s segmenta√ß√£o √© de 100 pixels. Ademais, dado que imagens 512 x 512 t√™m mais de 260 mil pixels, as imagens com a maior quantidade de pixels para a regi√£o do pulm√£o n√£o ocupam nem metade de todos os pixels da imagem.

![Histrograma da quantidade de pixels das fatias selcionadas ap√≥s segmenta√ß√£o das CTS pulmonares da base de dados ATM'22.](https://github.com/julia-cdp/dgm-2024.2/tree/readme_e2/projetos/PulmoNet/figs/histograma_fatias.png?raw=true)

A figura abaixo ilustra exemplos de fatias em regi√µes distintas deste histograma para podermos visualizar a variabilidade dos dados de entrada da rede.
Nota-se que as fatias com menos de 10 mil pixels para descrever o pulm√£o praticamente n√£o t√™m regi√£o suficiente para ser preenchida com vias a√©reas, ao passo que as imagens com mais pixels para a regi√£o do pulm√£o s√£o aqueles que mais pr√≥ximas de uma fatia no meio do pulm√£o, exibindo a maior √°rea util deste √≥rg√£o.
Com base nestas an√°lises, considera-se descartar imagens com poucos pixels para o pulm√£o.

![Exemplos de fatias das CTS pulmonares da base de dados ATM'22 segmentadas.](https://github.com/julia-cdp/dgm-2024.2/tree/readme_e2/projetos/PulmoNet/figs/exemplos_pixels.png?raw=true)

Al√©m da segmenta√ß√£o dos dados e sele√ß√£o das fatias, a base de dados tamb√©m passa pelas etapas de normaliza√ß√£o e de transforma√ß√£o para numpy arrays, antes de serem utilizados pelas GANs implementadas para este projeto.

### Workflow
O fluxo de trabalho proposto por este projeto, ilustrado na figura a seguir, inicia-se com a obten√ß√£o da base de dados ATM'22 e seu devido tratamento, conforme detalhado na se√ß√£o anterior.
Utilizando os dados de treinamento e valida√ß√£o, alimenta-se a rede generativa com as fatias segmentadas (m√°scaras bin√°rias). J√° a rede discriminadora recebe os dados reais (sem segmenta√ß√£o) e os dados sint√©ticos, devendo classificar cada um como "real" ou "falso".
Ap√≥s o treinamento, avalia-se os dados sint√©ticos a partir de tr√™s perspectivas: an√°lise qualitativa, an√°lise quantitativa e an√°lise de utilidade, as quais ser√£o descritas em detalhes nas pr√≥ximas se√ß√µes deste relat√≥rio.

![Fluxo para treinamento da PulmoNet.](https://github.com/julia-cdp/dgm-2024.2/tree/readme_e2/projetos/PulmoNet/figs/worflow_completo.png?raw=true)

Destaca-se que, em opera√ß√£o (ap√≥s a fase treinamento), espera-se que o modelo receba m√°scaras bin√°rias com o formato do pulm√£o e um ru√≠do, retonando o preenchimento da √°rea interna do pulm√£o.
Uma mesma m√°scara bin√°ria poder√° gerar imagens sint√©ticas distintas, devido o ru√≠do aleat√≥rio adicionado na entrada do modelo.
Os dados sint√©ticos dever√£o ser bons o suficiente para ajudarem no treinamento de modelo de segmenta√ß√£o das vias a√©reas e potencialmente substituir o uso de dados reais, para a preserva√ß√£o da privacidade dos pacientes.

Ademais, na fase atual do projeto, ainda n√£o estamos somando um ru√≠do aleat√≥rio √†s fatias segmentadas na entrada do gerador, mas este passo est√° mapeado para as pr√≥ximas etapas do projeto.

### Ferramentas Relevantes
A ferramenta escolhida para o desenvolvimento da arquitetura dos modelos e de treinamento √© o **PyTorch**, em fun√ß√£o de sua relev√¢ncia na √°rea e familiaridade por parte dos integrantes do grupo.
Ademais, para o desenvolvimento colaborativo dos modelos entre os estudantes, opta-se pela ferramenta de programa√ß√£o **Google Collaboratory**.
J√° para o versionamento dos modelos e para ajustar seus hiperpar√¢metros, decidiu-se pela ferramenta **Weights & Biases (Wandb AI)** dentre as op√ß√µes dispon√≠veis no mercado. E, al√©m disso, a ferramenta do **GitHub** tamb√©m auxiliar√° no versionamento dos algoritmos desenvolvidos.

### M√©tricas de Avalia√ß√£o
Para avaliar a qualidade dos resultados obtidos com o modelo de s√≠ntese, prop√µe-se tr√™s tipos de avalia√ß√£o: an√°lise qualitativa, an√°lise quantitativa e an√°lise de utilidade

#### An√°lise Qualitativa
Esta estrat√©gia ser√° utilizada apenas nas etapas iniciais do desenvolvimento do projeto, na qual os pr√≥prios estudantes ir√£o observar os resultados sint√©ticos, sejam eles imagens e/ou  volumes, e comparar√£o com os dados reais esperados. Com isto, faz-se uma avalia√ß√£o se a imagem gerada estaria muito distante de um CT pulmonar ou se o modelo j√° estaria se encaminhando para bons resultados. Ap√≥s esta etapa, as avalia√ß√µes do modelo ser√£o feitas por meio das an√°lises quantitativa e de utiliddade.

#### An√°lise Quantitativa
J√° a an√°lise quantitativa trata de uma avalia√ß√£o sobre as imagens a partir dos m√©todos Fr√©chet Inception Distance (FID) e Structural Similarity Index (SSIM), os quais s√£o utilizados para avalia√ß√£o de qualidade das imagens sint√©ticas e de similaridade com dados reais. Ambas estrat√©gias foram utilizadas pelos pesquisadores do artigo [[1]](#1), o que permite uma avalia√ß√£o dos nossos resultados frente a esta outra pesquisa.

> FID: InceptionV3  + The generated and real images from the test set were passed through the encoder, where the distributions of the generated and real images were calculated and used to compute the FID distance.

> SSIM: SSIM was used in order to compare each image with its ground-truth counterpart and uses three image characteristics to compare two images: luminance, contrast distortion and loss of structural correlation

> Gerar gr√°fico com distribui√ß√£o real e distribui√ß√£o sint√©tica, usadas no c√°lculo da FID. Podemos comparar nossos resultados dessa m√©trica com os resultados do artigo 1

#### An√°lise de Utilidade / Aplicabilidade
> Passar dados pelo lungmask e comparar com a m√°scara que originou o dado

> Utilidade do gerador: feature extraction -> Parecida com o dcgan: Usar uma U-Net com a mesma estrutura da nossa pix-2-pix para fazer a segmenta√ß√£o das vias a√©reas. Mostrar que nossa pix-2-pix ser√° mais capaz de fazer a segmenta√ß√£o devido a extra√ß√£o de suas features.

> juntar com o t√≥pico acima!! -> Por √∫ltimo, a an√°lise de benchmark, que tamb√©m pode ser considerada um estrat√©gia quantitativa, tem como proposta a compara√ß√£o das sa√≠das de uma rede de segmenta√ß√£o j√° consolidada a partir dos dados gerados pela PulmoNet e de dados reais. Feito isso, compara-se ambas as sa√≠das da rede, por meio do c√°lculo do coeficiente DICE (obtido a partir da precis√£o e recall da predi√ß√£o) e da quantidade de ramifica√ß√µes (m√©tricas escolhidas com base na refer√™ncia do artigo [[2]](#2)) e avalia-se se os dados sint√©ticos s√£o bons o suficiente em uma aplica√ß√£o real, isto √©, avalia-se a utilidade do modelo generativo proposto.

> Ver se o tempo de segmenta√ß√£o diminui com nossa gan 

> ----------------------------------------------------------

> Para 3D (caso de tempo), podemos fazer o lance interpola√ß√£o

### Cronograma

| N¬∫ da Tarefa | Descri√ß√£o                                                                 | Data Prevista de Finaliza√ß√£o | Semanas Entre Etapas |
|--------------|---------------------------------------------------------------------------|------------------------------|----------------------|
| 1            | Leitura de artigos, familiariza√ß√£o com a base de dados e GANs              | 10/09                        |                      |
| 2            | Primeira vers√£o da GAN (inspirada no artigo de refer√™ncia)                | 24/09                        | 2 semanas            |
| 3            | Estrutura de avalia√ß√£o bem delimitada                                     | 07/10                        | 2 semanas            |
| 4            | E2                                                                        | 08/10                        | 1 dia                |
| 5            | Primeiros resultados com imagens segmentadas e valores para valida√ß√£o     | 15/10                        | 1 semana             |
| 6            | Fine-tuning e aperfei√ßoamento do modelo                                   | 29/10                        | 2 semanas            |
| 7            | Evoluir para redes 3D ou continuar aperfei√ßoando o modelo                 | 05/11                        | 1 semana             |
| 8            | E3                                                                        | 25/11                        | 3 semanas            |



## Experimentos, Resultados e Discuss√£o dos Resultados

> Na entrega parcial do projeto (E2), essa se√ß√£o pode conter resultados parciais, explora√ß√µes de implementa√ß√µes realizadas e 
> discuss√µes sobre tais experimentos, incluindo decis√µes de mudan√ßa de trajet√≥ria ou descri√ß√£o de novos experimentos, como resultado dessas explora√ß√µes.

> Na entrega final do projeto (E3), essa se√ß√£o dever√° elencar os **principais** resultados obtidos (n√£o necessariamente todos), que melhor representam o cumprimento
> dos objetivos do projeto.

> A discuss√£o dos resultados pode ser realizada em se√ß√£o separada ou integrada √† se√ß√£o de resultados. Isso √© uma quest√£o de estilo.
> Considera-se fundamental que a apresenta√ß√£o de resultados n√£o sirva como um tratado que tem como √∫nico objetivo mostrar que "se trabalhou muito".
> O que se espera da se√ß√£o de resultados √© que ela **apresente e discuta** somente os resultados mais **relevantes**, que mostre os **potenciais e/ou limita√ß√µes** da metodologia, que destaquem aspectos
> de **performance** e que contenha conte√∫do que possa ser classificado como **compartilhamento organizado, did√°tico e reprodut√≠vel de conhecimento relevante para a comunidade**. 

## Conclus√£o

> A se√ß√£o de Conclus√£o deve ser uma se√ß√£o que recupera as principais informa√ß√µes j√° apresentadas no relat√≥rio e que aponta para trabalhos futuros.
> Na entrega parcial do projeto (E2) pode conter informa√ß√µes sobre quais etapas ou como o projeto ser√° conduzido at√© a sua finaliza√ß√£o.
> Na entrega final do projeto (E3) espera-se que a conclus√£o elenque, dentre outros aspectos, possibilidades de continuidade do projeto.

## Refer√™ncias Bibliogr√°ficas

<a id="1">[1]</a> : Jos√© Mendes et al., Lung CT image synthesis using GANs, Expert Systems with Applications, vol. 215, 2023, pp. 119350., https://www.sciencedirect.com/science/article/pii/S0957417422023685.

<a id="2">[2]</a> : Minghui Zhang et al., Multi-site, Multi-domain Airway Tree Modeling (ATM'22): A Public Benchmark for Pulmonary Airway Segmentation, https://arxiv.org/abs/2303.05745.

<a id="3">[3]</a> :  Jacopo Lenkowicz et al., A deep learning approach to generate synthetic CT in low field MR-guided radiotherapy for lung cases, Radiotherapy and Oncology, vol. 176, 2022, pp. 31-38, https://www.sciencedirect.com/science/article/pii/S0167814022042608.

<a id="4">[4]</a> : Swati P. Pawar and Sanjay N. Talbar, LungSeg-Net: Lung field segmentation using generative adversarial network, Biomedical Signal Processing and Control, vol. 64, 2021, 102296, https://www.sciencedirect.com/science/article/pii/S1746809420304158.

<a id="5">[5]</a> : Tekatli, Hil√¢l et al. ‚ÄúArtificial intelligence-assisted quantitative CT analysis of airway changes following SABR for central lung tumors.‚Äù Radiotherapy and oncology : journal of the European Society for Therapeutic Radiology and Oncology vol. 198 (2024): 110376. doi:10.1016/j.radonc.2024.110376, https://pubmed.ncbi.nlm.nih.gov/38857700/

<a id="6">[6]</a> : Zhang, Ling et al. ‚ÄúGeneralizing Deep Learning for Medical Image Segmentation to Unseen Domains via Deep Stacked Transformation.‚Äù IEEE transactions on medical imaging vol. 39,7 (2020): 2531-2540. doi:10.1109/TMI.2020.2973595, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7393676/

<a id="7">[7]</a> : Hofmanninger, J., Prayer, F., Pan, J. et al. Automatic lung segmentation in routine imaging is primarily a data diversity problem, not a methodology problem. Eur Radiol Exp 4, 50 (2020). https://doi.org/10.1186/s41747-020-00173-2

<a id="8">[8]</a> : Isola, P., Zhu, J. Y., Zhou, T., & Efros, A. A. (2017). Image-to-image translation with conditional adversarial networks. In Proceedings - 30th IEEE conference on computer vision and pattern recognition, CVPR 2017. http://dx.doi.org/10.1109/CVPR.2017. 632, arXiv:1611.07004.

Documento com as refer√™ncias extras identificadas: https://docs.google.com/document/d/1uatPj6byVIEVrvMuvbII6J6-5usOjf8RLrSxLHJ8u58/edit?usp=sharing
